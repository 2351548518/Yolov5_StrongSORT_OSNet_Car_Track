# 车辆测速算法及代码解读

## 算法流程

首先使用**提前设定好的车辆真实宽度和检测出来的车辆像素宽度求出真实距离和像素距离的比值为c**，再使用每辆车的前后两帧框的中心坐标计算出两帧之间移动的像素距离。利用这个比值和像素距离做映射，就可以求出两帧之间车辆移动的真实距离。然后距离除以两帧之间的时间，就是速度了。本测速算法中将车辆真实移动距离与像素移动距离看成是线性关系，仅在监控相机轴线与车辆移动方向垂直时才能成立，并且检测出来的车辆框在空间上会产生一定形变，使得真实距离和像素距离的映射关系不准确。有兴趣的同学可以在代码中加入透视变换，将图像变成类似于遥感数据的俯瞰图，实现测速后再将图像变换为原始图像视角，就能实现比较准确的车辆测速了。

$$ speed = c \frac{* \frac{\sqrt[2]{(x_1 - x_2)^2+(y_1 -y_2)^2}} { width} * 5}{\frac{1}{fps}} *3.6 = c * \frac{\sqrt[2]{(x_1 - x_2)^2+(y_1 -y_2)^2}} { width} * 5*fps *3.6 $$

c代表常数

5 表示车辆的一般长度

3.6表示从 m/s转换成km/h

## 核心代码

我的项目将测速代码封装到了Estimated_speed()函数里面，有详细注释，调用即可。

```python
def Estimated_speed(locations, fps, width):
    present_IDs = []
    prev_IDs = []
    work_IDs = []
    work_IDs_index = []
    work_IDs_prev_index = []
    work_locations = []  # 当前帧数据：中心点x坐标、中心点y坐标、目标序号、车辆类别、车辆像素宽度
    work_prev_locations = []  # 上一帧数据，数据格式相同
    speed = []
    for i in range(len(locations[1])):
        present_IDs.append(locations[1][i][2])  # 获得当前帧中跟踪到车辆的ID
    for i in range(len(locations[0])):
        prev_IDs.append(locations[0][i][2])  # 获得前一帧中跟踪到车辆的ID
    for m, n in enumerate(present_IDs):
        if n in prev_IDs:  # 进行筛选，找到在两帧图像中均被检测到的有效车辆ID，存入work_IDs中
            work_IDs.append(n)
            work_IDs_index.append(m)
    for x in work_IDs_index:  # 将当前帧有效检测车辆的信息存入work_locations中
        work_locations.append(locations[1][x])
    for y, z in enumerate(prev_IDs):
        if z in work_IDs:  # 将前一帧有效检测车辆的ID索引存入work_IDs_prev_index中
            work_IDs_prev_index.append(y)
    for x in work_IDs_prev_index:  # 将前一帧有效检测车辆的信息存入work_prev_locations中
        work_prev_locations.append(locations[0][x])
    for i in range(len(work_IDs)):
        speed.append(
            math.sqrt((work_locations[i][0] - work_prev_locations[i][0]) ** 2 +  # 计算有效检测车辆的速度，采用线性的从像素距离到真实空间距离的映射
                      (work_locations[i][1] - work_prev_locations[i][1]) ** 2) *  # 当视频拍摄视角并不垂直于车辆移动轨迹时，测算出来的速度将比实际速度低
            width[work_locations[i][3]] / (work_locations[i][4]) * fps / 5 * 3.6 * 2)
    for i in range(len(speed)):
        speed[i] = [round(speed[i], 1), work_locations[i][2]]  # 将保留一位小数的单位为km/h的车辆速度及其ID存入speed二维列表中
    return speed

```

## 效果展示

将计算出来的速度实时显示在车辆正上方。若超速，则发出警告。

## 自己完善

outputs的内容

```python
# 这里是结果
bboxes = output[0:4]
id = output[4]
cls = output[5]
bbox_left = output[0]
bbox_top = output[1]
bbox_w = output[2] - output[0]
bbox_h = output[3] - output[1]
```

增加：

测量当前物体速度。

```python
bbox_speed = Estimated_speed(outputs_prev[-2], output, id, fps, bbox_width) # 测量速度
```

保留上一帧的状态。

```python
if len(outputs_prev) < 2:
    outputs_prev.append(outputs[i])
else:
    outputs_prev[:] = [outputs_prev[-1], outputs[i]]
```

修改：只测量当前物体的速度。

```python
def Estimated_speed(outputs, output, id, fps, width):
    prev_IDs = []  # 之前的ids
    work_IDs = []  # 有效的ids
    work_locations = output  # 当前帧数据：中心点x坐标、中心点y坐标、目标序号、车辆类别、车辆像素宽度
    work_prev_locations = []  # 上一帧数据，数据格式相同
    for i in range(len(outputs)):
        prev_IDs.append(outputs[i][4])  # 获得前一帧中跟踪到车辆的ID
    for m, n in enumerate(prev_IDs):  # 进行筛选，找到在两帧图像中均被检测到的有效车辆ID，存入work_IDs中
        if id == n:
            work_IDs.append(m)
            work_prev_locations = outputs[m]  # 将当前帧有效检测车辆的信息存入work_locations中
    if len(work_IDs) > 0:
        speed = (math.sqrt((work_locations[0] - work_prev_locations[0]) ** 2 +  # 计算有效检测车辆的速度，采用线性的从像素距离到真实空间距离的映射
                           (work_locations[1] - work_prev_locations[1]) ** 2) *  # 当视频拍摄视角并不垂直于车辆移动轨迹时，测算出来的速度将比实际速度低
                 width * fps / 5 * 3.6 * 2)
        # speed = 11.3
        speed = str(round(speed, 1))
        return speed
    return "unknown"
```



